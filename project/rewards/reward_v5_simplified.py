# rewards/reward_v5_simplified.py - ç®€åŒ–ä¿®å¤ç‰ˆ

import numpy as np

def compute_reward(info, reward_config):
    """
    ç®€åŒ–ä¿®å¤åçš„å¥–åŠ±å‡½æ•°
    
    ä¸»è¦æ”¹è¿›ï¼š
    1. âœ… ç®€åŒ–å¤æ‚çš„é€»è¾‘åˆ†æ”¯
    2. âœ… ç¡®ä¿å¥–åŠ±è®¡ç®—çš„å¯é¢„æµ‹æ€§
    3. âœ… ä¿®å¤Edge-awareä¼˜åŠ¿ä½“ç°ä¸æ˜æ˜¾çš„é—®é¢˜
    4. âœ… æ”¹è¿›æé™å‹åŠ›åœºæ™¯çš„å¥–åŠ±æœºåˆ¶
    """
    
    try:
        # åŸºç¡€å‚æ•°è·å–
        base_reward = reward_config.get("base_reward", 10.0)
        penalty = reward_config.get("penalty", 20.0)
        
        # è·å–æƒé‡ï¼ˆæ”¯æŒè‡ªé€‚åº”æƒé‡ï¼‰
        adaptive_weights = info.get('adaptive_weights', {})
        pressure_level = info.get('pressure_level', 'medium')
        is_edge_aware = info.get('is_edge_aware', False)
        
        if adaptive_weights:
            sar_weight = adaptive_weights.get('sar_weight', 0.5)
            latency_weight = adaptive_weights.get('latency_weight', 0.3)
            efficiency_weight = adaptive_weights.get('efficiency_weight', 0.15)
            quality_weight = adaptive_weights.get('quality_weight', 0.05)
        else:
            sar_weight = reward_config.get("sar_weight", 0.5)
            latency_weight = reward_config.get("latency_weight", 0.3)
            efficiency_weight = reward_config.get("efficiency_weight", 0.15)
            quality_weight = reward_config.get("quality_weight", 0.05)
        
        # âœ… ä¿®å¤ï¼šè®¡ç®—åŸºç¡€æŒ‡æ ‡
        total_vnfs = info.get("total_vnfs", 0)
        deployed_vnfs = info.get("deployed_vnfs", 0)
        
        # å¤„ç†VNFæ•°é‡è·å–å¤±è´¥çš„æƒ…å†µ
        if total_vnfs == 0 and "paths" in info:
            total_vnfs = len(info.get("vnf_requests", []))
            deployed_vnfs = len(info.get("paths", []))
        
        if total_vnfs == 0:
            print("âŒ æ— æ³•è·å–VNFä»»åŠ¡ä¿¡æ¯")
            return -penalty
        
        # è®¡ç®—SARï¼ˆæœåŠ¡æ¥å—ç‡ï¼‰
        sar = deployed_vnfs / total_vnfs
        
        print(f"ğŸ“Š å¥–åŠ±è®¡ç®—: SAR={sar:.3f}, å‹åŠ›={pressure_level}, Edge-aware={is_edge_aware}")
        
        # ==== 1. SARå¥–åŠ±ï¼ˆæœ€é‡è¦ï¼‰====
        sar_reward = _compute_sar_reward(sar, sar_weight, pressure_level)
        
        # ==== 2. å»¶è¿Ÿå¥–åŠ± ====
        latency_reward = 0.0
        if "paths" in info and info["paths"]:
            avg_delay = _extract_avg_delay(info["paths"])
            latency_reward = _compute_latency_reward(avg_delay, latency_weight, pressure_level, reward_config)
        
        # ==== 3. æ•ˆç‡å¥–åŠ± ====
        efficiency_reward = _compute_efficiency_reward(info, efficiency_weight, pressure_level)
        
        # ==== 4. è´¨é‡å¥–åŠ±ï¼ˆEdge-awareä¼˜åŠ¿ä½“ç°ï¼‰====
        quality_reward = _compute_quality_reward(info, quality_weight, is_edge_aware, pressure_level)
        
        # ==== 5. å®Œæˆå¥–åŠ± ====
        completion_bonus = 0.0
        if sar >= 1.0:  # å®Œå…¨æˆåŠŸ
            completion_bonus = reward_config.get("completion_bonus", 15.0)
            # å‹åŠ›é€‚åº”æ€§å¥–åŠ±
            if pressure_level in ['high', 'extreme']:
                completion_bonus *= 1.5
        
        # âœ… è®¡ç®—æ€»å¥–åŠ±
        total_reward = (base_reward + 
                       sar_reward + 
                       latency_reward + 
                       efficiency_reward + 
                       quality_reward + 
                       completion_bonus)
        
        # ç¡®ä¿å¥–åŠ±åœ¨åˆç†èŒƒå›´å†…
        total_reward = max(total_reward, -penalty * 2)
        total_reward = min(total_reward, 200.0)  # è®¾ç½®ä¸Šé™é˜²æ­¢è¿‡å¤§
        
        # æ‰“å°å¥–åŠ±è¯¦æƒ…
        print(f"ğŸ’° å¥–åŠ±è¯¦æƒ…:")
        print(f"   åŸºç¡€: {base_reward:.2f}")
        print(f"   SAR: {sar_reward:.2f} (æƒé‡: {sar_weight:.2f})")
        print(f"   å»¶è¿Ÿ: {latency_reward:.2f} (æƒé‡: {latency_weight:.2f})")
        print(f"   æ•ˆç‡: {efficiency_reward:.2f} (æƒé‡: {efficiency_weight:.2f})")
        print(f"   è´¨é‡: {quality_reward:.2f} (æƒé‡: {quality_weight:.2f})")
        print(f"   å®Œæˆ: {completion_bonus:.2f}")
        print(f"   æ€»è®¡: {total_reward:.2f}")
        
        return float(total_reward)
        
    except Exception as e:
        print(f"âŒ å¥–åŠ±è®¡ç®—å¤±è´¥: {e}")
        return float(reward_config.get("base_reward", 10.0))


def _compute_sar_reward(sar: float, sar_weight: float, pressure_level: str) -> float:
    """è®¡ç®—SARå¥–åŠ± - ç®€åŒ–ç‰ˆ"""
    # åŸºç¡€SARå¥–åŠ±ï¼ˆçº¿æ€§ï¼‰
    base_sar_reward = sar * 100 * sar_weight
    
    # å‹åŠ›é€‚åº”æ€§è°ƒæ•´
    if pressure_level == 'extreme':
        # æé™å‹åŠ›ä¸‹ï¼Œä»»ä½•æˆåŠŸéƒ½å€¼å¾—å¥–åŠ±
        if sar > 0.3:
            pressure_bonus = (sar - 0.3) * 50 * sar_weight
            base_sar_reward += pressure_bonus
    elif pressure_level == 'high':
        # é«˜å‹åŠ›ä¸‹ï¼Œé€‚åº¦å¥–åŠ±
        if sar > 0.5:
            pressure_bonus = (sar - 0.5) * 30 * sar_weight
            base_sar_reward += pressure_bonus
    
    return base_sar_reward


def _extract_avg_delay(paths) -> float:
    """æå–å¹³å‡å»¶è¿Ÿ"""
    try:
        delays = []
        for path in paths:
            delay = path.get("delay", 0)
            if delay > 0:
                delays.append(delay)
        
        return np.mean(delays) if delays else 0.0
        
    except Exception as e:
        print(f"âŒ å»¶è¿Ÿæå–å¤±è´¥: {e}")
        return 0.0


def _compute_latency_reward(avg_delay: float, latency_weight: float, pressure_level: str, reward_config: dict) -> float:
    """è®¡ç®—å»¶è¿Ÿå¥–åŠ± - ç®€åŒ–ç‰ˆ"""
    if avg_delay <= 0:
        return 0.0
    
    # æ ¹æ®å‹åŠ›è°ƒæ•´å»¶è¿Ÿæ ‡å‡†
    if pressure_level == 'extreme':
        excellent_latency = 150.0  # æ”¾å®½æ ‡å‡†
        acceptable_latency = 300.0
    elif pressure_level == 'high':
        excellent_latency = 100.0
        acceptable_latency = 200.0
    else:
        excellent_latency = reward_config.get("excellent_latency", 30.0)
        acceptable_latency = reward_config.get("acceptable_latency", 80.0)
    
    # ç®€åŒ–çš„å»¶è¿Ÿè¯„åˆ†
    if avg_delay <= excellent_latency:
        latency_score = 1.0
    elif avg_delay <= acceptable_latency:
        latency_score = 1.0 - (avg_delay - excellent_latency) / (acceptable_latency - excellent_latency)
    else:
        latency_score = 0.0
    
    return latency_score * 100 * latency_weight


def _compute_efficiency_reward(info: dict, efficiency_weight: float, pressure_level: str) -> float:
    """è®¡ç®—æ•ˆç‡å¥–åŠ± - ç®€åŒ–ç‰ˆ"""
    try:
        resource_util = info.get("resource_utilization", 0.0)
        
        # æ ¹æ®å‹åŠ›è°ƒæ•´æ•ˆç‡æœŸæœ›
        if pressure_level == 'extreme':
            target_util = 0.3  # æé™å‹åŠ›ä¸‹ï¼Œä½åˆ©ç”¨ç‡ä¹Ÿæ˜¯å¥½çš„
            tolerance = 0.4
        elif pressure_level == 'high':
            target_util = 0.5
            tolerance = 0.3
        else:
            target_util = 0.7  # æ­£å¸¸æƒ…å†µä¸‹è¿½æ±‚é«˜åˆ©ç”¨ç‡
            tolerance = 0.2
        
        # è®¡ç®—æ•ˆç‡å¾—åˆ†
        util_diff = abs(resource_util - target_util)
        if util_diff <= tolerance:
            efficiency_score = 1.0 - (util_diff / tolerance) * 0.5
        else:
            efficiency_score = 0.5 - min((util_diff - tolerance) / tolerance, 0.5)
        
        efficiency_score = max(0.0, efficiency_score)
        
        return efficiency_score * 100 * efficiency_weight
        
    except Exception as e:
        print(f"âŒ æ•ˆç‡è®¡ç®—å¤±è´¥: {e}")
        return 0.0


def _compute_quality_reward(info: dict, quality_weight: float, is_edge_aware: bool, pressure_level: str) -> float:
    """
    è®¡ç®—è´¨é‡å¥–åŠ± - ä¿®å¤Edge-awareä¼˜åŠ¿ä½“ç°
    """
    try:
        quality_reward = 0.0
        
        if is_edge_aware:
            # âœ… Edge-awareç‰ˆæœ¬çš„è´¨é‡ä¼˜åŠ¿
            print("ğŸ¯ Edge-awareè´¨é‡è¯„ä¼°")
            
            # åŸºç¡€è´¨é‡å¥–åŠ±ï¼ˆå‡è®¾Edge-awareåœ¨è´¨é‡æ§åˆ¶ä¸Šæœ‰ä¼˜åŠ¿ï¼‰
            base_quality_reward = 50 * quality_weight
            
            # ä»è·¯å¾„ä¿¡æ¯æå–è´¨é‡æ•°æ®
            if "paths" in info and info["paths"]:
                avg_jitter, avg_loss = _extract_quality_metrics(info["paths"])
                
                # è´¨é‡æ§åˆ¶å¥–åŠ±
                jitter_score = max(0, 1.0 - avg_jitter / 0.1)  # æŠ–åŠ¨æ§åˆ¶
                loss_score = max(0, 1.0 - avg_loss / 0.05)     # ä¸¢åŒ…æ§åˆ¶
                
                quality_control_reward = (jitter_score + loss_score) * 25 * quality_weight
                base_quality_reward += quality_control_reward
                
                print(f"   æŠ–åŠ¨æ§åˆ¶: {avg_jitter:.4f} -> å¾—åˆ†: {jitter_score:.2f}")
                print(f"   ä¸¢åŒ…æ§åˆ¶: {avg_loss:.4f} -> å¾—åˆ†: {loss_score:.2f}")
            
            # å‹åŠ›é€‚åº”æ€§å¥–åŠ±
            if pressure_level in ['high', 'extreme']:
                pressure_adaptation_bonus = 30 * quality_weight
                base_quality_reward += pressure_adaptation_bonus
                print(f"   {pressure_level}å‹åŠ›é€‚åº”å¥–åŠ±: {pressure_adaptation_bonus:.2f}")
            
            quality_reward = base_quality_reward
            
        else:
            # Baselineç‰ˆæœ¬ - ç›¸å¯¹åŠ£åŠ¿
            print("ğŸ“Š Baselineè´¨é‡è¯„ä¼°")
            
            # Baselineåœ¨æŸäº›åœºæ™¯ä¸‹çš„åŠ£åŠ¿
            if pressure_level == 'low':
                quality_penalty = 10 * quality_weight
                quality_reward = -quality_penalty
                print(f"   ä½å‹åŠ›åœºæ™¯BaselineåŠ£åŠ¿: -{quality_penalty:.2f}")
            elif pressure_level in ['high', 'extreme']:
                quality_penalty = 15 * quality_weight
                quality_reward = -quality_penalty
                print(f"   {pressure_level}å‹åŠ›åœºæ™¯BaselineåŠ£åŠ¿: -{quality_penalty:.2f}")
        
        return quality_reward
        
    except Exception as e:
        print(f"âŒ è´¨é‡å¥–åŠ±è®¡ç®—å¤±è´¥: {e}")
        return 0.0


def _extract_quality_metrics(paths) -> tuple:
    """æå–è´¨é‡æŒ‡æ ‡"""
    try:
        jitters = []
        losses = []
        
        for path in paths:
            jitter = path.get("jitter", 0.0)
            loss = path.get("loss", 0.0)
            
            if jitter > 0:
                jitters.append(jitter)
            if loss > 0:
                losses.append(loss)
        
        avg_jitter = np.mean(jitters) if jitters else 0.0
        avg_loss = np.mean(losses) if losses else 0.0
        
        return avg_jitter, avg_loss
        
    except Exception as e:
        print(f"âŒ è´¨é‡æŒ‡æ ‡æå–å¤±è´¥: {e}")
        return 0.0, 0.0


# âœ… æ–°å¢ï¼šæ›´ç®€å•çš„å¥–åŠ±å‡½æ•°é€‰é¡¹
def compute_reward_simple(info, reward_config):
    """
    è¶…ç®€åŒ–å¥–åŠ±å‡½æ•° - ç”¨äºè°ƒè¯•
    """
    try:
        total_vnfs = info.get("total_vnfs", 1)
        deployed_vnfs = info.get("deployed_vnfs", 0)
        
        if total_vnfs == 0:
            return -10.0
        
        sar = deployed_vnfs / total_vnfs
        is_edge_aware = info.get('is_edge_aware', False)
        
        # åŸºç¡€SARå¥–åŠ±
        sar_reward = sar * 100
        
        # Edge-awareå¥–åŠ±
        edge_bonus = 20 if is_edge_aware and sar > 0.8 else 0
        
        # å»¶è¿Ÿæƒ©ç½š
        avg_delay = _extract_avg_delay(info.get("paths", []))
        latency_penalty = min(avg_delay / 10, 20) if avg_delay > 0 else 0
        
        total_reward = sar_reward + edge_bonus - latency_penalty
        
        print(f"ğŸ”§ ç®€åŒ–å¥–åŠ±: SAR={sar:.2f}*100={sar_reward:.1f} + Edge={edge_bonus} - å»¶è¿Ÿ={latency_penalty:.1f} = {total_reward:.1f}")
        
        return float(total_reward)
        
    except Exception as e:
        print(f"âŒ ç®€åŒ–å¥–åŠ±è®¡ç®—å¤±è´¥: {e}")
        return 10.0


# âœ… æµ‹è¯•å‡½æ•°
def test_reward_functions():
    """æµ‹è¯•å¥–åŠ±å‡½æ•°"""
    print("ğŸ§ª æµ‹è¯•å¥–åŠ±å‡½æ•°...")
    
    base_config = {
        "base_reward": 10.0,
        "sar_weight": 0.5,
        "latency_weight": 0.3,
        "efficiency_weight": 0.15,
        "quality_weight": 0.05,
        "excellent_latency": 30.0,
        "completion_bonus": 20.0
    }
    
    # æµ‹è¯•åœºæ™¯1: Edge-awareæˆåŠŸæ¡ˆä¾‹
    test_info_edge = {
        'total_vnfs': 3,
        'deployed_vnfs': 3,
        'is_edge_aware': True,
        'pressure_level': 'normal',
        'paths': [
            {'delay': 25.0, 'jitter': 0.005, 'loss': 0.001},
            {'delay': 30.0, 'jitter': 0.008, 'loss': 0.002},
            {'delay': 28.0, 'jitter': 0.006, 'loss': 0.001}
        ],
        'resource_utilization': 0.7
    }
    
    print("\nğŸ“‹ æµ‹è¯•1: Edge-awareæ­£å¸¸åœºæ™¯")
    reward1 = compute_reward(test_info_edge, base_config)
    print(f"ç»“æœ: {reward1:.2f}")
    
    # æµ‹è¯•åœºæ™¯2: Baselineå¯¹æ¯”
    test_info_baseline = test_info_edge.copy()
    test_info_baseline['is_edge_aware'] = False
    
    print("\nğŸ“‹ æµ‹è¯•2: Baselineæ­£å¸¸åœºæ™¯")
    reward2 = compute_reward(test_info_baseline, base_config)
    print(f"ç»“æœ: {reward2:.2f}")
    print(f"Edge-awareä¼˜åŠ¿: {reward1 - reward2:.2f}")
    
    # æµ‹è¯•åœºæ™¯3: æé™å‹åŠ›åœºæ™¯
    test_info_extreme = {
        'total_vnfs': 5,
        'deployed_vnfs': 2,
        'is_edge_aware': True,
        'pressure_level': 'extreme',
        'paths': [
            {'delay': 120.0, 'jitter': 0.02, 'loss': 0.01},
            {'delay': 150.0, 'jitter': 0.025, 'loss': 0.015}
        ],
        'resource_utilization': 0.3
    }
    
    print("\nğŸ“‹ æµ‹è¯•3: æé™å‹åŠ›åœºæ™¯")
    reward3 = compute_reward(test_info_extreme, base_config)
    print(f"ç»“æœ: {reward3:.2f}")
    
    # æµ‹è¯•åœºæ™¯4: ç®€åŒ–å¥–åŠ±å‡½æ•°
    print("\nğŸ“‹ æµ‹è¯•4: ç®€åŒ–å¥–åŠ±å‡½æ•°")
    reward4 = compute_reward_simple(test_info_edge, base_config)
    print(f"ç»“æœ: {reward4:.2f}")
    
    print("\nâœ… å¥–åŠ±å‡½æ•°æµ‹è¯•å®Œæˆ!")
    
    return {
        'edge_aware_normal': reward1,
        'baseline_normal': reward2,
        'edge_aware_extreme': reward3,
        'simplified': reward4
    }


if __name__ == "__main__":
    test_reward_functions()