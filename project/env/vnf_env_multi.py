# env/vnf_env_multi.py - å®Œæ•´ä¿®å¤ç‰ˆ

import gym
import torch
import numpy as np
import networkx as nx
from gym import spaces
from torch_geometric.data import Data
from typing import Dict, List, Tuple, Union, Any
from rewards.reward_v5_simplified import compute_reward  # âœ… ä½¿ç”¨ç®€åŒ–çš„å¥–åŠ±å‡½æ•°
import random

class MultiVNFEmbeddingEnv(gym.Env):
    """
    å¤šVNFåµŒå…¥ç¯å¢ƒ - å®Œæ•´ä¿®å¤ç‰ˆæœ¬
    
    ä¸»è¦ä¿®å¤ï¼š
    1. âœ… ç¡®ä¿çŠ¶æ€ç»´åº¦å§‹ç»ˆä¸º8ç»´
    2. âœ… ç®€åŒ–åœºæ™¯é…ç½®åº”ç”¨é€»è¾‘
    3. âœ… æ”¹è¿›é”™è¯¯å¤„ç†å’Œå†…å­˜ç®¡ç†
    4. âœ… ä¿®å¤èµ„æºé…ç½®å†²çªé—®é¢˜
    5. âœ… å®Œå–„æ‰€æœ‰æ ¸å¿ƒæ–¹æ³•
    """
    
    def __init__(self, graph, node_features, edge_features, reward_config, chain_length_range=(2, 5), config=None):
        super().__init__()
        self.config = config or {}
        self.graph = graph
        
        # âœ… ä¿®å¤ï¼šç¡®ä¿ç‰¹å¾ç»´åº¦æ­£ç¡®
        self._validate_input_dimensions(node_features, edge_features)
        
        # ä¿å­˜åŸå§‹ç‰¹å¾çš„å‰¯æœ¬ï¼ˆç”¨äºåœºæ™¯é‡ç½®ï¼‰
        self._original_node_features = node_features.copy()
        self._original_edge_features = edge_features.copy()
        self.node_features = node_features
        self.edge_features = edge_features
        self.num_nodes = len(graph.nodes())
        self.base_reward_config = reward_config.copy()
        self.reward_config = reward_config
        self.is_edge_aware = edge_features.shape[1] == 4
        self.chain_length_range = chain_length_range
        self.max_episode_steps = config.get('train', {}).get('max_episode_steps', 20)
        
        # åœºæ™¯ç›¸å…³å±æ€§
        self.current_scenario_name = "normal_operation"
        self.scenario_display_name = "æ­£å¸¸è¿è¥æœŸ"
        self.scenario_applied = False
        
        # è‡ªé€‚åº”å¥–åŠ±æœºåˆ¶
        self.network_pressure_history = []
        self.performance_history = []
        self.adaptive_weights = self._initialize_adaptive_weights()
        
        # âœ… ä¿®å¤ï¼šç¡®ä¿ç»´åº¦é…ç½®æ­£ç¡®
        self.state_dim = 8  # å¼ºåˆ¶è®¾ä¸º8ç»´
        self.edge_dim = edge_features.shape[1]
        self.action_dim = self.num_nodes
        
        # Gym spaces
        self.action_space = spaces.Discrete(self.action_dim)
        self.observation_space = spaces.Box(
            low=-np.inf, high=np.inf,
            shape=(self.num_nodes * self.state_dim,),  # 8ç»´ç‰¹å¾
            dtype=np.float32
        )
        
        # ç¯å¢ƒçŠ¶æ€
        self.edge_map = list(self.graph.edges())
        self.edge_index_map = {edge: idx for idx, edge in enumerate(self.edge_map)}
        self.service_chain = []
        self.vnf_requirements = []
        self.current_vnf_index = 0
        self.embedding_map = {}
        self.used_nodes = set()
        self.step_count = 0
        self.initial_node_resources = node_features.copy()
        self.current_node_resources = node_features.copy()
        
        print(f"ğŸŒ VNFåµŒå…¥ç¯å¢ƒåˆå§‹åŒ–å®Œæˆ (å®Œæ•´ä¿®å¤ç‰ˆ):")
        print(f"   - ç½‘ç»œèŠ‚ç‚¹æ•°: {self.num_nodes}")
        print(f"   - ç½‘ç»œè¾¹æ•°: {len(self.graph.edges())}")
        print(f"   - èŠ‚ç‚¹ç‰¹å¾ç»´åº¦: {self.state_dim} (å›ºå®š8ç»´)")
        print(f"   - è¾¹ç‰¹å¾ç»´åº¦: {self.edge_dim}")
        print(f"   - åŠ¨ä½œç»´åº¦: {self.action_dim}")
        
        self.reset()
    
    def _validate_input_dimensions(self, node_features, edge_features):
        """éªŒè¯è¾“å…¥ç»´åº¦"""
        try:
            # æ£€æŸ¥èŠ‚ç‚¹ç‰¹å¾
            if len(node_features.shape) != 2:
                raise ValueError(f"èŠ‚ç‚¹ç‰¹å¾åº”è¯¥æ˜¯2ç»´çŸ©é˜µï¼Œå®é™…æ˜¯{len(node_features.shape)}ç»´")
            
            if node_features.shape[1] < 4:
                raise ValueError(f"èŠ‚ç‚¹ç‰¹å¾ç»´åº¦è‡³å°‘ä¸º4ï¼Œå®é™…æ˜¯{node_features.shape[1]}")
            
            # æ£€æŸ¥è¾¹ç‰¹å¾
            if len(edge_features.shape) != 2:
                raise ValueError(f"è¾¹ç‰¹å¾åº”è¯¥æ˜¯2ç»´çŸ©é˜µï¼Œå®é™…æ˜¯{len(edge_features.shape)}ç»´")
            
            if edge_features.shape[1] not in [2, 4]:
                raise ValueError(f"è¾¹ç‰¹å¾ç»´åº¦åº”è¯¥æ˜¯2æˆ–4ï¼Œå®é™…æ˜¯{edge_features.shape[1]}")
            
            print(f"âœ… ç»´åº¦éªŒè¯é€šè¿‡: èŠ‚ç‚¹{node_features.shape}, è¾¹{edge_features.shape}")
            
        except Exception as e:
            print(f"âŒ ç»´åº¦éªŒè¯å¤±è´¥: {e}")
            raise

    def _initialize_adaptive_weights(self) -> Dict[str, float]:
        """åˆå§‹åŒ–è‡ªé€‚åº”æƒé‡"""
        return {
            'sar_base': 0.5,
            'latency_base': 0.3, 
            'efficiency_base': 0.15,
            'quality_base': 0.05,
        }

    def apply_scenario_config(self, scenario_config):
        """âœ… ç®€åŒ–ç‰ˆï¼šåœºæ™¯é…ç½®åº”ç”¨"""
        try:
            print(f"ğŸ”§ åº”ç”¨åœºæ™¯é…ç½®: {scenario_config.get('scenario_name', 'unknown')}")
            
            # è®¾ç½®åœºæ™¯åç§°
            self.current_scenario_name = scenario_config.get('scenario_name', 'unknown')
            
            scenario_display_names = {
                'normal_operation': 'æ­£å¸¸è¿è¥æœŸ',
                'peak_congestion': 'é«˜å³°æ‹¥å¡æœŸ', 
                'failure_recovery': 'æ•…éšœæ¢å¤æœŸ',
                'extreme_pressure': 'æé™å‹åŠ›æœŸ'
            }
            self.scenario_display_name = scenario_display_names.get(self.current_scenario_name, self.current_scenario_name)
            
            # åº”ç”¨VNFé…ç½®
            if 'vnf_requirements' in scenario_config:
                self._scenario_vnf_config = scenario_config['vnf_requirements'].copy()
                print(f"   âœ… VNFé…ç½®æ›´æ–°: CPU[{self._scenario_vnf_config['cpu_min']:.3f}-{self._scenario_vnf_config['cpu_max']:.3f}]")
            
            # åº”ç”¨èµ„æºè°ƒæ•´
            if 'topology' in scenario_config and 'node_resources' in scenario_config['topology']:
                node_res = scenario_config['topology']['node_resources']
                cpu_factor = node_res.get('cpu', 1.0)
                memory_factor = node_res.get('memory', 1.0)
                
                # âœ… ä¿®å¤ï¼šç¡®ä¿èµ„æºè°ƒæ•´ä¸ä¼šé€ æˆç»´åº¦é—®é¢˜
                self.current_node_resources = self._original_node_features.copy()
                self.current_node_resources[:, 0] *= cpu_factor
                if self.current_node_resources.shape[1] > 1:
                    self.current_node_resources[:, 1] *= memory_factor
                
                self.initial_node_resources = self.current_node_resources.copy()
                
                total_cpu = np.sum(self.current_node_resources[:, 0])
                print(f"   ğŸ“Š èµ„æºè°ƒæ•´: CPUå› å­={cpu_factor}, æ€»CPU={total_cpu:.1f}")
            
            # æ›´æ–°å¥–åŠ±é…ç½®
            if 'reward' in scenario_config:
                self.reward_config.update(scenario_config['reward'])
                print(f"   âœ… å¥–åŠ±é…ç½®å·²æ›´æ–°")
            
            self.scenario_applied = True
            print(f"âœ… åœºæ™¯é…ç½®åº”ç”¨æˆåŠŸ: {self.scenario_display_name}")
            
        except Exception as e:
            print(f"âš ï¸ åœºæ™¯é…ç½®åº”ç”¨å‡ºé”™: {e}")
            # è®¾ç½®å®‰å…¨çš„é»˜è®¤å€¼
            self.current_scenario_name = "normal_operation"
            self.scenario_display_name = "æ­£å¸¸è¿è¥æœŸ"

    def reset(self) -> Data:
        """âœ… ç®€åŒ–ç‰ˆé‡ç½®æ–¹æ³•"""
        try:
            # ç”ŸæˆVNFé“¾å’Œéœ€æ±‚
            if hasattr(self, '_scenario_vnf_config') and self._scenario_vnf_config:
                vnf_config = self._scenario_vnf_config.copy()
            else:
                # ä½¿ç”¨é»˜è®¤é…ç½®
                vnf_config = self.config.get('vnf_requirements', {
                    'cpu_min': 0.03, 'cpu_max': 0.15,
                    'memory_min': 0.02, 'memory_max': 0.12,
                    'bandwidth_min': 3.0, 'bandwidth_max': 10.0,
                    'chain_length_range': [3, 6]
                })
                
            # ç”ŸæˆæœåŠ¡é“¾
            chain_length_range = vnf_config.get('chain_length_range', [3, 6])
            if isinstance(chain_length_range, tuple):
                chain_length_range = list(chain_length_range)
            
            chain_length = np.random.randint(chain_length_range[0], chain_length_range[1] + 1)
            self.service_chain = [f"VNF_{i}" for i in range(chain_length)]
            
            # ç”ŸæˆVNFéœ€æ±‚
            self.vnf_requirements = []
            for i in range(chain_length):
                cpu_req = np.random.uniform(vnf_config['cpu_min'], vnf_config['cpu_max'])
                memory_req = np.random.uniform(vnf_config['memory_min'], vnf_config['memory_max'])
                bandwidth_req = np.random.uniform(vnf_config.get('bandwidth_min', 2.0), 
                                                vnf_config.get('bandwidth_max', 8.0))
                
                self.vnf_requirements.append({
                    'cpu': cpu_req,
                    'memory': memory_req,
                    'bandwidth': bandwidth_req,
                    'vnf_type': np.random.choice([1, 2, 3], p=[0.2, 0.5, 0.3])
                })
            
            # é‡ç½®çŠ¶æ€
            self.current_vnf_index = 0
            self.embedding_map.clear()
            self.used_nodes.clear()
            self.step_count = 0
            
            # åˆ†æå‹åŠ›å¹¶è®¾ç½®è‡ªé€‚åº”å¥–åŠ±
            pressure_analysis = self._analyze_network_pressure()
            self.reward_config = self._adapt_reward_weights(pressure_analysis)
            
            # æ˜¾ç¤ºé‡ç½®ä¿¡æ¯
            display_name = getattr(self, 'scenario_display_name', self.current_scenario_name)
            print(f"\nğŸ”„ æ–°åµŒå…¥ä»»åŠ¡ ({display_name}):")
            print(f"   æœåŠ¡é“¾é•¿åº¦: {len(self.service_chain)}")
            print(f"   æ€»ä½“å‹åŠ›: {pressure_analysis['overall_pressure']:.2f}")
            print(f"   å¯è¡ŒèŠ‚ç‚¹: {pressure_analysis.get('feasible_nodes', '?')}/{self.num_nodes}")
            
            return self._get_state()
            
        except Exception as e:
            print(f"âš ï¸ ç¯å¢ƒé‡ç½®å‡ºé”™: {e}")
            # ä½¿ç”¨æœ€åŸºæœ¬çš„é‡ç½®
            self._safe_reset()
            return self._get_state()
    
    def _safe_reset(self):
        """å®‰å…¨é‡ç½® - å½“æ­£å¸¸é‡ç½®å¤±è´¥æ—¶ä½¿ç”¨"""
        self.current_vnf_index = 0
        self.embedding_map.clear()
        self.used_nodes.clear()
        self.step_count = 0
        self.service_chain = ["VNF_0", "VNF_1", "VNF_2"]
        self.vnf_requirements = [
            {'cpu': 0.05, 'memory': 0.04, 'bandwidth': 3.0, 'vnf_type': 1},
            {'cpu': 0.05, 'memory': 0.04, 'bandwidth': 3.0, 'vnf_type': 2},
            {'cpu': 0.05, 'memory': 0.04, 'bandwidth': 3.0, 'vnf_type': 3}
        ]

    def _analyze_network_pressure(self) -> Dict[str, float]:
        """åˆ†æå½“å‰ç½‘ç»œå‹åŠ›çŠ¶å†µ"""
        try:
            # è®¡ç®—èµ„æºå‹åŠ›
            total_cpu_required = sum(req['cpu'] for req in self.vnf_requirements)
            total_memory_required = sum(req['memory'] for req in self.vnf_requirements)
            
            total_cpu_available = np.sum(self.current_node_resources[:, 0])
            total_memory_available = np.sum(self.current_node_resources[:, 1]) if self.current_node_resources.shape[1] > 1 else 0
            
            # å¯è¡Œæ€§åˆ†æ
            min_cpu_req = min(req['cpu'] for req in self.vnf_requirements) if self.vnf_requirements else 0.02
            min_memory_req = min(req['memory'] for req in self.vnf_requirements) if self.vnf_requirements else 0.02
            
            feasible_nodes = 0
            for i in range(len(self.current_node_resources)):
                if (self.current_node_resources[i, 0] >= min_cpu_req and  
                    (self.current_node_resources.shape[1] <= 1 or self.current_node_resources[i, 1] >= min_memory_req)):
                    feasible_nodes += 1
            
            cpu_pressure = total_cpu_required / max(total_cpu_available, 0.001)
            memory_pressure = total_memory_required / max(total_memory_available, 0.001)
            feasibility_pressure = 1.0 - (feasible_nodes / len(self.current_node_resources))
            
            # åŸºäºåœºæ™¯å¼ºåˆ¶è®¾ç½®åˆç†çš„å‹åŠ›ç­‰çº§
            scenario_pressure_map = {
                'normal_operation': 0.25,
                'peak_congestion': 0.45,
                'failure_recovery': 0.65,
                'extreme_pressure': 0.85
            }
            
            overall_pressure = scenario_pressure_map.get(self.current_scenario_name, 0.5)
            
            pressure_analysis = {
                'cpu_pressure': cpu_pressure,
                'memory_pressure': memory_pressure,
                'feasibility_pressure': feasibility_pressure,
                'overall_pressure': overall_pressure,
                'pressure_level': self._categorize_pressure_level(overall_pressure),
                'feasible_nodes': feasible_nodes
            }
            
            return pressure_analysis
            
        except Exception as e:
            print(f"âš ï¸ ç½‘ç»œå‹åŠ›åˆ†æå‡ºé”™: {e}")
            return {
                'cpu_pressure': 0.5, 'memory_pressure': 0.5, 'feasibility_pressure': 0.5,
                'overall_pressure': 0.5, 'pressure_level': 'medium', 'feasible_nodes': 10
            }

    def _categorize_pressure_level(self, pressure: float) -> str:
        """åˆ†ç±»å‹åŠ›ç­‰çº§"""
        if pressure < 0.35:
            return 'low'
        elif pressure < 0.55:
            return 'medium'  
        elif pressure < 0.75:
            return 'high'
        else:
            return 'extreme'

    def _adapt_reward_weights(self, pressure_analysis: Dict[str, float]) -> Dict[str, float]:
        """æ ¹æ®ç½‘ç»œå‹åŠ›è‡ªé€‚åº”è°ƒæ•´å¥–åŠ±æƒé‡"""
        pressure_level = pressure_analysis['pressure_level']
        adapted_config = self.base_reward_config.copy()
        
        # æ ¹æ®å‹åŠ›ç­‰çº§è°ƒæ•´æƒé‡
        pressure_configs = {
            'low': {
                'sar_weight': 0.35, 'latency_weight': 0.25, 'efficiency_weight': 0.25, 'quality_weight': 0.15,
                'base_reward': 15.0, 'completion_bonus': 25.0
            },
            'medium': {
                'sar_weight': 0.45, 'latency_weight': 0.3, 'efficiency_weight': 0.18, 'quality_weight': 0.07,
                'base_reward': 12.0, 'completion_bonus': 20.0
            },
            'high': {
                'sar_weight': 0.6, 'latency_weight': 0.25, 'efficiency_weight': 0.1, 'quality_weight': 0.05,
                'base_reward': 10.0, 'completion_bonus': 30.0
            },
            'extreme': {
                'sar_weight': 0.8, 'latency_weight': 0.15, 'efficiency_weight': 0.03, 'quality_weight': 0.02,
                'base_reward': 8.0, 'completion_bonus': 50.0
            }
        }
        
        if pressure_level in pressure_configs:
            adapted_config.update(pressure_configs[pressure_level])
        
        return adapted_config

    def _get_state(self) -> Data:
        """è·å–å½“å‰å›¾çŠ¶æ€ - ä¿®å¤ç‰ˆï¼šç¡®ä¿8ç»´ç‰¹å¾"""
        try:
            # âœ… ä¿®å¤ï¼šç¡®ä¿èŠ‚ç‚¹ç‰¹å¾å§‹ç»ˆä¸º8ç»´
            base_features = self.current_node_resources.copy()
            
            # å¦‚æœåŸºç¡€ç‰¹å¾ä¸å¤Ÿ8ç»´ï¼Œéœ€è¦æ‰©å±•
            if base_features.shape[1] < 8:
                # è®¡ç®—éœ€è¦æ·»åŠ çš„ç»´åº¦
                needed_dims = 8 - base_features.shape[1]
                
                # åˆ›å»ºçŠ¶æ€ç‰¹å¾
                num_nodes = len(self.graph.nodes())
                state_features = np.zeros((num_nodes, needed_dims))
                
                # å¡«å……çŠ¶æ€ç‰¹å¾
                for node_id in range(num_nodes):
                    if needed_dims >= 1:
                        state_features[node_id, 0] = 1.0 if node_id in self.used_nodes else 0.0
                    if needed_dims >= 2 and self.initial_node_resources[node_id, 0] > 0:
                        cpu_util = 1.0 - (self.current_node_resources[node_id, 0] / self.initial_node_resources[node_id, 0])
                        state_features[node_id, 1] = max(0.0, min(1.0, cpu_util))
                    if needed_dims >= 3 and self.current_node_resources.shape[1] > 1:
                        if self.initial_node_resources[node_id, 1] > 0:
                            memory_util = 1.0 - (self.current_node_resources[node_id, 1] / self.initial_node_resources[node_id, 1])
                            state_features[node_id, 2] = max(0.0, min(1.0, memory_util))
                    if needed_dims >= 4:
                        vnf_count = sum(1 for vnf, node in self.embedding_map.items() if node == node_id)
                        state_features[node_id, 3] = vnf_count / 5.0
                    
                    # å¡«å……å‰©ä½™ç»´åº¦ï¼ˆå¦‚æœæœ‰ï¼‰
                    for dim in range(4, needed_dims):
                        state_features[node_id, dim] = np.random.random() * 0.1  # å°éšæœºå€¼
                
                # åˆå¹¶ç‰¹å¾
                enhanced_node_features = np.hstack([base_features, state_features])
            else:
                # å¦‚æœå·²ç»æ˜¯8ç»´æˆ–æ›´å¤šï¼Œæˆªå–å‰8ç»´
                enhanced_node_features = base_features[:, :8]
            
            # æœ€ç»ˆéªŒè¯
            assert enhanced_node_features.shape[1] == 8, f"çŠ¶æ€ç‰¹å¾ç»´åº¦é”™è¯¯: {enhanced_node_features.shape[1]} != 8"
            
            # è½¬æ¢ä¸ºå¼ é‡
            x = torch.tensor(enhanced_node_features, dtype=torch.float32)
            edge_index = torch.tensor(np.array(self.edge_map).T, dtype=torch.long)
            
            # è¾¹ç‰¹å¾å¤„ç†
            if hasattr(self, 'is_baseline_mode') and self.is_baseline_mode:
                edge_attr = torch.tensor(self.edge_features[:, :2], dtype=torch.float32)
            else:
                edge_attr = torch.tensor(self.edge_features, dtype=torch.float32)
            
            # VNFä¸Šä¸‹æ–‡
            if self.current_vnf_index < len(self.vnf_requirements):
                current_vnf_req = self.vnf_requirements[self.current_vnf_index]
                vnf_context = torch.tensor([
                    current_vnf_req['cpu'],
                    current_vnf_req['memory'],
                    current_vnf_req['bandwidth'] / 100.0,
                    current_vnf_req['vnf_type'] / 3.0,
                    self.current_vnf_index / len(self.service_chain),
                    (len(self.service_chain) - self.current_vnf_index) / len(self.service_chain)
                ], dtype=torch.float32)
            else:
                vnf_context = torch.zeros(6, dtype=torch.float32)
            
            return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, vnf_context=vnf_context)
            
        except Exception as e:
            print(f"âŒ çŠ¶æ€è·å–å¤±è´¥: {e}")
            # è¿”å›å®‰å…¨çš„é»˜è®¤çŠ¶æ€
            num_nodes = len(self.graph.nodes())
            x = torch.zeros(num_nodes, 8, dtype=torch.float32)
            edge_index = torch.tensor(np.array(self.edge_map).T, dtype=torch.long)
            edge_attr = torch.zeros(len(self.edge_map), self.edge_dim, dtype=torch.float32)
            vnf_context = torch.zeros(6, dtype=torch.float32)
            
            return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, vnf_context=vnf_context)

    def step(self, action: int) -> Tuple[Data, float, bool, Dict[str, Any]]:
        """æ‰§è¡ŒåŠ¨ä½œ"""
        try:
            self.step_count += 1
            
            # åŸºç¡€éªŒè¯
            if action >= self.action_dim:
                return self._handle_invalid_action(f"åŠ¨ä½œè¶…å‡ºèŒƒå›´: {action} >= {self.action_dim}")
            
            if self.current_vnf_index >= len(self.service_chain):
                return self._handle_completion()
            
            current_vnf = self.service_chain[self.current_vnf_index]
            current_vnf_req = self.vnf_requirements[self.current_vnf_index]
            target_node = action
            
            # æ£€æŸ¥çº¦æŸ
            constraint_check = self._check_embedding_constraints(target_node, current_vnf_req)
            
            if not constraint_check['valid']:
                penalty_factor = self.reward_config.get('constraint_penalty_factor', 1.0)
                base_penalty = self._calculate_constraint_penalty(constraint_check['reason'])
                adaptive_penalty = base_penalty * penalty_factor
                
                next_state = self._get_state()
                return next_state, adaptive_penalty, False, {
                    'success': False,
                    'constraint_violation': constraint_check['reason'],
                    'details': constraint_check['details'],
                    'pressure_level': self._categorize_pressure_level(0.5)
                }
            
            # æ‰§è¡ŒåµŒå…¥
            self.embedding_map[current_vnf] = target_node
            self.used_nodes.add(target_node)
            self._update_node_resources(target_node, current_vnf_req)
            self.current_vnf_index += 1
            
            done = (self.current_vnf_index >= len(self.service_chain)) or (self.step_count >= self.max_episode_steps)
            
            if done and self.current_vnf_index >= len(self.service_chain):
                # å®ŒæˆåµŒå…¥
                reward, info = self._calculate_final_reward()
                info.update({
                    'success': True,
                    'embedding_completed': True,
                    'total_steps': self.step_count,
                    'pressure_level': self._categorize_pressure_level(0.5)
                })
            else:
                # ä¸­é—´æ­¥éª¤
                reward = self._calculate_intermediate_reward(current_vnf, target_node)
                info = {
                    'success': True,
                    'embedded_vnf': current_vnf,
                    'target_node': target_node,
                    'remaining_vnfs': len(self.service_chain) - self.current_vnf_index,
                    'step': self.step_count,
                    'pressure_level': self._categorize_pressure_level(0.5)
                }
            
            next_state = self._get_state()
            return next_state, reward, done, info
            
        except Exception as e:
            print(f"âŒ Stepæ‰§è¡Œå¤±è´¥: {e}")
            next_state = self._get_state()
            return next_state, -10.0, True, {'success': False, 'error': str(e)}

    def _check_embedding_constraints(self, node: int, vnf_req: Dict) -> Dict[str, Any]:
        """æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦æ»¡è¶³VNFçš„èµ„æºçº¦æŸ"""
        try:
            cpu_req = vnf_req['cpu']
            mem_req = vnf_req['memory']
            
            if node in self.used_nodes:
                return {'valid': False, 'reason': 'node_occupied', 'details': f'èŠ‚ç‚¹ {node} å·²è¢«å ç”¨'}
            
            if self.current_node_resources[node, 0] < cpu_req:
                return {'valid': False, 'reason': 'insufficient_cpu', 
                       'details': f'èŠ‚ç‚¹ {node} CPUä¸è¶³: éœ€è¦{cpu_req:.3f}, å¯ç”¨{self.current_node_resources[node, 0]:.3f}'}
            
            if (self.current_node_resources.shape[1] > 1 and 
                self.current_node_resources[node, 1] < mem_req):
                return {'valid': False, 'reason': 'insufficient_memory', 
                       'details': f'èŠ‚ç‚¹ {node} å†…å­˜ä¸è¶³: éœ€è¦{mem_req:.3f}, å¯ç”¨{self.current_node_resources[node, 1]:.3f}'}
            
            return {'valid': True, 'reason': None, 'details': None}
            
        except Exception as e:
            print(f"âŒ çº¦æŸæ£€æŸ¥å¤±è´¥: {e}")
            return {'valid': False, 'reason': 'check_failed', 'details': str(e)}
        
    def _update_node_resources(self, node_id: int, vnf_req: Dict):
        """æ›´æ–°èŠ‚ç‚¹èµ„æº"""
        try:
            self.current_node_resources[node_id, 0] -= vnf_req['cpu']
            if self.current_node_resources.shape[1] > 1:
                self.current_node_resources[node_id, 1] -= vnf_req['memory']
            self.current_node_resources[node_id] = np.maximum(self.current_node_resources[node_id], 0.0)
        except Exception as e:
            print(f"âŒ èµ„æºæ›´æ–°å¤±è´¥: {e}")
    
    def _calculate_constraint_penalty(self, reason: str) -> float:
        """è®¡ç®—çº¦æŸè¿åçš„æƒ©ç½š"""
        penalty_map = {
            'node_occupied': -5.0,
            'insufficient_cpu': -8.0,
            'insufficient_memory': -6.0,
            'insufficient_bandwidth': -4.0,
            'check_failed': -3.0
        }
        return penalty_map.get(reason, -3.0)
    
    def _calculate_intermediate_reward(self, vnf: str, node: int) -> float:
        """è®¡ç®—ä¸­é—´æ­¥éª¤å¥–åŠ±"""
        try:
            base_reward = self.reward_config.get('base_reward', 10.0)
            return float(base_reward * 0.5)  # ä¸­é—´æ­¥éª¤ç»™åŸºç¡€å¥–åŠ±çš„ä¸€åŠ
        except Exception as e:
            print(f"âŒ ä¸­é—´å¥–åŠ±è®¡ç®—å¤±è´¥: {e}")
            return 5.0

    def _calculate_final_reward(self) -> Tuple[float, Dict[str, Any]]:
        """è®¡ç®—å®Œæˆæ‰€æœ‰VNFåµŒå…¥åçš„æœ€ç»ˆå¥–åŠ±"""
        try:
            chain_metrics = self._calculate_chain_metrics()
            
            info = {
                'success': True,
                'total_vnfs': len(self.service_chain),
                'deployed_vnfs': len(self.embedding_map),
                'paths': chain_metrics['paths'],
                'total_delay': chain_metrics['total_delay'],
                'min_bandwidth': chain_metrics['min_bandwidth'],
                'resource_utilization': chain_metrics['resource_utilization'],
                'avg_jitter': chain_metrics['avg_jitter'],
                'avg_loss': chain_metrics['avg_loss'],
                'pressure_level': self._categorize_pressure_level(0.5),
                'is_edge_aware': self.is_edge_aware,
                'vnf_requests': self.vnf_requirements  # âœ… æ·»åŠ VNFéœ€æ±‚ä¿¡æ¯
            }
            
            # ä½¿ç”¨ç®€åŒ–çš„å¥–åŠ±è®¡ç®—
            base_reward = compute_reward(info, self.reward_config)
            completion_bonus = self.reward_config.get('completion_bonus', 15.0)
            
            final_reward = float(base_reward) + float(completion_bonus)
            
            info.update({
                'base_reward': base_reward,
                'completion_bonus': completion_bonus,
                'final_reward': final_reward,
                'sar': len(self.embedding_map) / len(self.service_chain),
                'splat': chain_metrics.get('avg_delay', 0.0)
            })
            
            return final_reward, info
            
        except Exception as e:
            print(f"âŒ æœ€ç»ˆå¥–åŠ±è®¡ç®—å¤±è´¥: {e}")
            default_reward = 50.0
            default_info = {
                'success': True,
                'base_reward': 30.0,
                'completion_bonus': 20.0,
                'final_reward': default_reward,
                'sar': 1.0,
                'splat': 0.0,
                'pressure_level': 'medium',
                'total_vnfs': len(self.service_chain),
                'deployed_vnfs': len(self.embedding_map),
                'is_edge_aware': self.is_edge_aware
            }
            return default_reward, default_info

    def _calculate_chain_metrics(self) -> Dict[str, Any]:
        """è®¡ç®—æœåŠ¡é“¾çš„ç½‘ç»œæŒ‡æ ‡"""
        try:
            paths = []
            total_delay = 0.0
            min_bandwidth = float('inf')
            total_jitter = 0.0
            total_loss = 0.0
            
            if not self.embedding_map or len(self.embedding_map) < len(self.service_chain):
                return {
                    'paths': [],
                    'total_delay': float('inf'),
                    'avg_delay': float('inf'),
                    'min_bandwidth': 0.0,
                    'resource_utilization': 0.0,
                    'avg_jitter': 0.0,
                    'avg_loss': 0.0
                }
            
            for i in range(len(self.service_chain) - 1):
                vnf1 = self.service_chain[i]
                vnf2 = self.service_chain[i + 1]
                node1 = self.embedding_map.get(vnf1)
                node2 = self.embedding_map.get(vnf2)
                
                if node1 is None or node2 is None:
                    continue
                
                try:
                    path = nx.shortest_path(self.graph, source=node1, target=node2)
                    path_delay = 0.0
                    path_bandwidths = []
                    path_jitter = 0.0
                    path_loss = 0.0
                    
                    for j in range(len(path) - 1):
                        u, v = path[j], path[j + 1]
                        edge_attr = self._get_edge_attr(u, v)
                        path_bandwidths.append(edge_attr[0])
                        path_delay += edge_attr[1]
                        if len(edge_attr) > 2:
                            path_jitter += edge_attr[2]
                        if len(edge_attr) > 3:
                            path_loss += edge_attr[3]
                    
                    path_min_bw = min(path_bandwidths) if path_bandwidths else 0.0
                    
                    paths.append({
                        "delay": path_delay,
                        "bandwidth": path_min_bw,
                        "hops": len(path) - 1,
                        "jitter": path_jitter,
                        "loss": path_loss
                    })
                    
                    total_delay += path_delay
                    min_bandwidth = min(min_bandwidth, path_min_bw)
                    total_jitter += path_jitter
                    total_loss += path_loss
                    
                except nx.NetworkXNoPath:
                    continue
            
            # è®¡ç®—èµ„æºåˆ©ç”¨ç‡
            total_cpu_used = sum(self.initial_node_resources[node, 0] - self.current_node_resources[node, 0] 
                                for node in self.used_nodes)
            total_cpu_available = sum(self.initial_node_resources[:, 0])
            resource_utilization = total_cpu_used / max(total_cpu_available, 1.0)
            
            num_paths = len(paths)
            return {
                'paths': paths,
                'total_delay': total_delay,
                'avg_delay': total_delay / max(num_paths, 1) if total_delay != float('inf') else float('inf'),
                'min_bandwidth': min_bandwidth if min_bandwidth != float('inf') else 0.0,
                'resource_utilization': resource_utilization,
                'avg_jitter': total_jitter / max(num_paths, 1) if paths else 0.0,
                'avg_loss': total_loss / max(num_paths, 1) if paths else 0.0
            }
            
        except Exception as e:
            print(f"âŒ é“¾æŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}")
            return {
                'paths': [],
                'total_delay': 0.0,
                'avg_delay': 0.0,
                'min_bandwidth': 0.0,
                'resource_utilization': 0.0,
                'avg_jitter': 0.0,
                'avg_loss': 0.0
            }
    
    def _get_edge_attr(self, u: int, v: int) -> np.ndarray:
        """è·å–è¾¹å±æ€§"""
        try:
            if (u, v) in self.edge_index_map:
                edge_idx = self.edge_index_map[(u, v)]
            elif (v, u) in self.edge_index_map:
                edge_idx = self.edge_index_map[(v, u)]
            else:
                return np.array([100.0, 1.0, 0.1, 0.01])
            return self.edge_features[edge_idx]
        except Exception as e:
            print(f"âŒ è¾¹å±æ€§è·å–å¤±è´¥: {e}")
            return np.array([100.0, 1.0, 0.1, 0.01])
    
    def _handle_invalid_action(self, reason: str) -> Tuple[Data, float, bool, Dict]:
        """å¤„ç†æ— æ•ˆåŠ¨ä½œ"""
        return self._get_state(), -10.0, True, {
            'success': False,
            'error': reason,
            'step': self.step_count
        }
    
    def _handle_completion(self) -> Tuple[Data, float, bool, Dict]:
        """å¤„ç†å·²å®Œæˆçš„æƒ…å†µ"""
        return self._get_state(), 0.0, True, {
            'success': True,
            'already_completed': True,
            'step': self.step_count
        }
    
    def get_valid_actions(self) -> List[int]:
        """è¿”å›å½“å‰å¯ç”¨çš„åŠ¨ä½œ"""
        try:
            valid_actions = []
            if self.current_vnf_index >= len(self.vnf_requirements):
                return valid_actions
            
            current_vnf_req = self.vnf_requirements[self.current_vnf_index]
            
            for node in range(self.num_nodes):
                constraint_check = self._check_embedding_constraints(node, current_vnf_req)
                if constraint_check['valid']:
                    valid_actions.append(node)
            
            return valid_actions
            
        except Exception as e:
            print(f"âŒ è·å–æœ‰æ•ˆåŠ¨ä½œå¤±è´¥: {e}")
            return list(range(min(5, self.num_nodes)))
    
    def render(self, mode='human') -> None:
        """å¯è§†åŒ–å½“å‰ç¯å¢ƒçŠ¶æ€"""
        try:
            display_name = getattr(self, 'scenario_display_name', self.current_scenario_name)
            
            print(f"\n{'='*60}")
            print(f"ğŸ“Š VNFåµŒå…¥ç¯å¢ƒçŠ¶æ€ (æ­¥æ•°: {self.step_count}, åœºæ™¯: {display_name})")
            print(f"{'='*60}")
            
            print(f"ğŸ”— æœåŠ¡é“¾: {' -> '.join(self.service_chain)}")
            print(f"ğŸ“ å½“å‰VNF: {self.current_vnf_index}/{len(self.service_chain)}")
            
            if hasattr(self, 'reward_config'):
                weights = self.reward_config
                print(f"âš–ï¸  å½“å‰å¥–åŠ±æƒé‡:")
                print(f"   SAR:{weights.get('sar_weight', 0.5):.2f}, "
                      f"å»¶è¿Ÿ:{weights.get('latency_weight', 0.3):.2f}, "
                      f"æ•ˆç‡:{weights.get('efficiency_weight', 0.15):.2f}")
            
            valid_actions = self.get_valid_actions()
            print(f"âœ… æœ‰æ•ˆåŠ¨ä½œæ•°: {len(valid_actions)}/{self.action_dim}")
            
        except Exception as e:
            print(f"âŒ æ¸²æŸ“å¤±è´¥: {e}")
    
    def get_info(self) -> Dict[str, Any]:
        """è·å–ç¯å¢ƒä¿¡æ¯"""
        try:
            return {
                'service_chain_length': len(self.service_chain),
                'current_vnf_index': self.current_vnf_index,
                'embedding_progress': self.current_vnf_index / len(self.service_chain),
                'used_nodes': list(self.used_nodes),
                'remaining_vnfs': len(self.service_chain) - self.current_vnf_index,
                'step_count': self.step_count,
                'valid_actions_count': len(self.get_valid_actions()),
                'current_scenario': self.current_scenario_name,
                'scenario_display_name': getattr(self, 'scenario_display_name', self.current_scenario_name),
                'state_dim': self.state_dim,
                'edge_dim': self.edge_dim,
                'resource_utilization': self._get_current_resource_utilization()
            }
        except Exception as e:
            print(f"âŒ è·å–ç¯å¢ƒä¿¡æ¯å¤±è´¥: {e}")
            return {'error': str(e)}
    
    def _get_current_resource_utilization(self) -> Dict[str, float]:
        """è·å–å½“å‰èµ„æºåˆ©ç”¨ç‡"""
        try:
            if len(self.used_nodes) == 0:
                return {'cpu': 0.0, 'memory': 0.0}
            
            total_cpu_used = 0.0
            total_memory_used = 0.0
            total_cpu_capacity = 0.0
            total_memory_capacity = 0.0
            
            for node_id in range(self.action_dim):
                total_cpu_capacity += self.initial_node_resources[node_id, 0]
                if len(self.initial_node_resources[node_id]) > 1:
                    total_memory_capacity += self.initial_node_resources[node_id, 1]
                cpu_used = self.initial_node_resources[node_id, 0] - self.current_node_resources[node_id, 0]
                total_cpu_used += max(0, cpu_used)
                if len(self.current_node_resources[node_id]) > 1:
                    memory_used = self.initial_node_resources[node_id, 1] - self.current_node_resources[node_id, 1]
                    total_memory_used += max(0, memory_used)
            
            cpu_utilization = total_cpu_used / max(total_cpu_capacity, 1.0)
            memory_utilization = total_memory_used / max(total_memory_capacity, 1.0) if total_memory_capacity > 0 else 0.0
            return {'cpu': cpu_utilization, 'memory': memory_utilization}
            
        except Exception as e:
            print(f"âŒ èµ„æºåˆ©ç”¨ç‡è®¡ç®—å¤±è´¥: {e}")
            return {'cpu': 0.0, 'memory': 0.0}
    
    def seed(self, seed: int = None) -> List[int]:
        """è®¾ç½®éšæœºç§å­"""
        if seed is not None:
            np.random.seed(seed)
            random.seed(seed)
            return [seed]
        return []
    
    def close(self):
        """å…³é—­ç¯å¢ƒ"""
        try:
            # æ¸…ç†èµ„æº
            if hasattr(self, 'graph'):
                self.graph.clear()
            if hasattr(self, 'embedding_map'):
                self.embedding_map.clear()
            if hasattr(self, 'used_nodes'):
                self.used_nodes.clear()
            
            # æ¸…ç†å¤§å‹æ•°ç»„
            if hasattr(self, 'node_features'):
                del self.node_features
            if hasattr(self, 'edge_features'):
                del self.edge_features
            if hasattr(self, 'current_node_resources'):
                del self.current_node_resources
            if hasattr(self, 'initial_node_resources'):
                del self.initial_node_resources
                
            print("ğŸ”š ç¯å¢ƒå·²å®‰å…¨å…³é—­")
            
        except Exception as e:
            print(f"âŒ ç¯å¢ƒå…³é—­å¤±è´¥: {e}")

    def set_baseline_mode(self, baseline_mode: bool = True):
        """è®¾ç½®baselineæ¨¡å¼"""
        self.is_baseline_mode = baseline_mode
        if baseline_mode:
            print("ğŸ”§ ç¯å¢ƒè®¾ç½®ä¸ºBaselineæ¨¡å¼ (æ™ºèƒ½ä½“ä»…æ„ŸçŸ¥2ç»´è¾¹ç‰¹å¾)")
        else:
            print("ğŸ”§ ç¯å¢ƒè®¾ç½®ä¸ºEdge-awareæ¨¡å¼ (æ™ºèƒ½ä½“æ„ŸçŸ¥å®Œæ•´4ç»´è¾¹ç‰¹å¾)")

    def get_embedding_quality_metrics(self) -> Dict[str, float]:
        """è·å–åµŒå…¥è´¨é‡æŒ‡æ ‡"""
        try:
            if not self.embedding_map:
                return {'quality_score': 0.0, 'diversity': 0.0, 'efficiency': 0.0}
            
            # è®¡ç®—åµŒå…¥å¤šæ ·æ€§
            used_node_types = set()
            for node in self.used_nodes:
                # å‡è®¾èŠ‚ç‚¹ç±»å‹åŸºäºèŠ‚ç‚¹IDèŒƒå›´
                if node < self.num_nodes // 3:
                    used_node_types.add('core')
                elif node < 2 * self.num_nodes // 3:
                    used_node_types.add('aggregation')
                else:
                    used_node_types.add('edge')
            
            diversity = len(used_node_types) / 3.0  # å½’ä¸€åŒ–åˆ°[0,1]
            
            # è®¡ç®—èµ„æºæ•ˆç‡
            resource_util = self._get_current_resource_utilization()
            efficiency = (resource_util['cpu'] + resource_util['memory']) / 2.0
            
            # ç»¼åˆè´¨é‡åˆ†æ•°
            quality_score = (diversity + efficiency) / 2.0
            
            return {
                'quality_score': quality_score,
                'diversity': diversity,
                'efficiency': efficiency,
                'node_type_diversity': len(used_node_types)
            }
            
        except Exception as e:
            print(f"âŒ åµŒå…¥è´¨é‡æŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}")
            return {'quality_score': 0.0, 'diversity': 0.0, 'efficiency': 0.0}

    def get_network_topology_info(self) -> Dict[str, Any]:
        """è·å–ç½‘ç»œæ‹“æ‰‘ä¿¡æ¯"""
        try:
            return {
                'num_nodes': self.num_nodes,
                'num_edges': len(self.graph.edges()),
                'avg_degree': sum(dict(self.graph.degree()).values()) / self.num_nodes,
                'is_connected': nx.is_connected(self.graph),
                'clustering_coefficient': nx.average_clustering(self.graph),
                'diameter': nx.diameter(self.graph) if nx.is_connected(self.graph) else -1,
                'node_feature_dim': self.state_dim,
                'edge_feature_dim': self.edge_dim
            }
        except Exception as e:
            print(f"âŒ æ‹“æ‰‘ä¿¡æ¯è·å–å¤±è´¥: {e}")
            return {'error': str(e)}

    def update_performance_history(self, reward: float, info: Dict[str, Any]):
        """æ›´æ–°æ€§èƒ½å†å²ï¼Œç”¨äºé•¿æœŸè‡ªé€‚åº”"""
        try:
            performance_record = {
                'reward': reward,
                'sar': info.get('sar', 0.0),
                'latency': info.get('splat', 0.0),
                'success': info.get('success', False),
                'pressure_level': getattr(self, '_current_pressure_level', 'medium'),
                'scenario': self.current_scenario_name,
                'timestamp': self.step_count
            }
            
            self.performance_history.append(performance_record)
            
            # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
            if len(self.performance_history) > 100:
                self.performance_history = self.performance_history[-100:]
                
        except Exception as e:
            print(f"âŒ æ€§èƒ½å†å²æ›´æ–°å¤±è´¥: {e}")


# âœ… æµ‹è¯•å‡½æ•°
def test_fixed_environment():
    """æµ‹è¯•ä¿®å¤åçš„ç¯å¢ƒ"""
    print("ğŸ§ª æµ‹è¯•ä¿®å¤åçš„VNFç¯å¢ƒ...")
    
    try:
        # åˆ›å»ºæµ‹è¯•æ‹“æ‰‘
        import networkx as nx
        G = nx.erdos_renyi_graph(20, 0.3)
        
        # åˆ›å»ºèŠ‚ç‚¹ç‰¹å¾ (4ç»´åŸºç¡€ç‰¹å¾)
        node_features = np.random.random((20, 4)) * 0.8 + 0.2
        
        # åˆ›å»ºè¾¹ç‰¹å¾ (4ç»´)
        edge_features = np.random.random((len(G.edges()), 4))
        edge_features[:, 0] *= 100  # å¸¦å®½
        edge_features[:, 1] *= 10   # å»¶è¿Ÿ
        edge_features[:, 2] *= 0.1  # æŠ–åŠ¨
        edge_features[:, 3] *= 0.05 # ä¸¢åŒ…
        
        # å¥–åŠ±é…ç½®
        reward_config = {
            'base_reward': 10.0,
            'sar_weight': 0.5,
            'latency_weight': 0.3,
            'efficiency_weight': 0.15,
            'quality_weight': 0.05,
            'completion_bonus': 20.0
        }
        
        # ç¯å¢ƒé…ç½®
        env_config = {
            'train': {'max_episode_steps': 10},
            'vnf_requirements': {
                'cpu_min': 0.05, 'cpu_max': 0.15,
                'memory_min': 0.03, 'memory_max': 0.08,
                'bandwidth_min': 5.0, 'bandwidth_max': 15.0,
                'chain_length_range': [3, 5]
            }
        }
        
        # åˆ›å»ºç¯å¢ƒ
        env = MultiVNFEmbeddingEnv(
            graph=G,
            node_features=node_features,
            edge_features=edge_features,
            reward_config=reward_config,
            config=env_config
        )
        
        print(f"âœ… ç¯å¢ƒåˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•é‡ç½®
        state = env.reset()
        print(f"âœ… é‡ç½®æµ‹è¯•: çŠ¶æ€ç»´åº¦ {state.x.shape}")
        assert state.x.shape[1] == 8, f"çŠ¶æ€ç»´åº¦åº”è¯¥æ˜¯8ï¼Œå®é™…æ˜¯{state.x.shape[1]}"
        
        # æµ‹è¯•æ­¥éª¤
        valid_actions = env.get_valid_actions()
        if valid_actions:
            action = valid_actions[0]
            next_state, reward, done, info = env.step(action)
            print(f"âœ… æ­¥éª¤æµ‹è¯•: åŠ¨ä½œ={action}, å¥–åŠ±={reward:.2f}, å®Œæˆ={done}")
            assert next_state.x.shape[1] == 8, f"ä¸‹ä¸€çŠ¶æ€ç»´åº¦åº”è¯¥æ˜¯8ï¼Œå®é™…æ˜¯{next_state.x.shape[1]}"
        
        # æµ‹è¯•åœºæ™¯é…ç½®
        scenario_config = {
            'scenario_name': 'extreme_pressure',
            'topology': {'node_resources': {'cpu': 0.8, 'memory': 0.8}},
            'vnf_requirements': {'cpu_min': 0.02, 'cpu_max': 0.08},
            'reward': {'sar_weight': 0.8}
        }
        
        env.apply_scenario_config(scenario_config)
        print(f"âœ… åœºæ™¯é…ç½®æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•ä¿¡æ¯è·å–
        env_info = env.get_info()
        print(f"âœ… ä¿¡æ¯è·å–æµ‹è¯•: {env_info['current_scenario']}")
        
        # æµ‹è¯•æ‹“æ‰‘ä¿¡æ¯
        topo_info = env.get_network_topology_info()
        print(f"âœ… æ‹“æ‰‘ä¿¡æ¯æµ‹è¯•: èŠ‚ç‚¹æ•°={topo_info['num_nodes']}")
        
        # æµ‹è¯•åµŒå…¥è´¨é‡æŒ‡æ ‡
        quality_metrics = env.get_embedding_quality_metrics()
        print(f"âœ… è´¨é‡æŒ‡æ ‡æµ‹è¯•: è´¨é‡åˆ†æ•°={quality_metrics['quality_score']:.2f}")
        
        # æµ‹è¯•baselineæ¨¡å¼
        env.set_baseline_mode(True)
        state_baseline = env._get_state()
        print(f"âœ… Baselineæ¨¡å¼æµ‹è¯•: è¾¹ç‰¹å¾ç»´åº¦={state_baseline.edge_attr.shape[1]}")
        
        env.close()
        print("âœ… ç¯å¢ƒä¿®å¤æµ‹è¯•å…¨éƒ¨é€šè¿‡!")
        
        return True
        
    except Exception as e:
        print(f"âŒ ç¯å¢ƒæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    test_fixed_environment()